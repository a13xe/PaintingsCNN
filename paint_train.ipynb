{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "from skimage.util import random_noise\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data/train' is the directory where your training images are stored\n",
    "data_train = 'data/train'\n",
    "\n",
    "def augment_images(image_paths, n_augmented=20, output_size=(64, 64)):\n",
    "    augmented_images = []\n",
    "    \n",
    "    # Randomly select 'n_augmented' images to augment\n",
    "    selected_image_paths = random.sample(image_paths, n_augmented)\n",
    "    \n",
    "    for image_path in selected_image_paths:\n",
    "        # Load the image\n",
    "        image = io.imread(image_path)\n",
    "\n",
    "        # Random 3D rotation (simulated with 2D rotation for simplicity)\n",
    "        angle = random.uniform(-5, 5)  # Random angle between -15 and 15 degrees\n",
    "        rotated_image = transform.rotate(image, angle, mode='wrap')\n",
    "\n",
    "        # Add random noise\n",
    "        noisy_image = random_noise(rotated_image, mode='gaussian')\n",
    "\n",
    "        # Resize the image\n",
    "        resized_image = transform.resize(noisy_image, output_size, anti_aliasing=True)\n",
    "\n",
    "        # Convert the image data type to uint8\n",
    "        final_image = (noisy_image * 255).astype(np.uint8)\n",
    "        \n",
    "        augmented_images.append(final_image)\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "# Get a list of image paths from the training directory\n",
    "image_paths = [os.path.join(data_train, filename) for filename in os.listdir(data_train) if filename.endswith('.png')]\n",
    "\n",
    "# Apply the 'augment_images' function to augment 20 images\n",
    "augmented_validation_images = augment_images(image_paths, n_augmented=20)\n",
    "\n",
    "# Save the augmented images to the 'data/validate' directory\n",
    "os.makedirs('data/validate', exist_ok=True)  # Make sure the validation directory exists\n",
    "for i, image in enumerate(augmented_validation_images):\n",
    "    io.imsave(f'data/validate/aug_{i}.png', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = io.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            # Keep only the first three channels (RGB)\n",
    "            img = img[:, :, :3]\n",
    "            images.append(img)\n",
    "            filenames.append(filename)\n",
    "    return images, filenames\n",
    "\n",
    "def preprocess_images(images, size=(64, 64)):\n",
    "    processed_images = []\n",
    "    for img in images:\n",
    "        # Ensure the image has three channels\n",
    "        if img.shape[-1] != 3:\n",
    "            continue\n",
    "        img_resized = transform.resize(img, size, anti_aliasing=True)\n",
    "        img_normalized = img_resized / 255.0\n",
    "        processed_images.append(img_normalized)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "# Load and preprocess images\n",
    "images, filenames = load_images_from_folder('data/train')\n",
    "images = preprocess_images(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: CNN Architecture and Transfer Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Develop three different architectures from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CNN Architecture and Transfer Learning\n",
    "def create_model_architecture(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create different architectures\n",
    "model_architectures = [create_model_architecture(images.shape[1:]) for _ in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Transfer learning for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CNN Architecture and Transfer Learning\n",
    "def create_model_architecture(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Create different architectures\n",
    "model_architectures = [create_model_architecture(images.shape[1:]) for _ in range(3)]\n",
    "create_model_architecture(images.shape[1:]).save('models/transfer_model_{i}.keras', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning for each model\n",
    "def apply_transfer_learning(model):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create a new model with the base model and custom layers\n",
    "    new_model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return new_model\n",
    "\n",
    "# Apply transfer learning and inspect the model summary\n",
    "transfer_model = apply_transfer_learning(create_model_architecture((64, 64, 3)))\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. CNN Training\n",
    "def train_model(model, images, train_labels, epochs=10, batch_size=32):\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(images, train_labels, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
    "    return history\n",
    "\n",
    "# Prepare train labels for binary classification (assuming you have two classes)\n",
    "train_labels = np.zeros(len(images))\n",
    "# For example, if the first half of your images are class 0 and the second half are class 1\n",
    "train_labels[len(images)//2:] = 1\n",
    "\n",
    "# Train the transfer learning model\n",
    "print(\"Training the transfer learning model...\")\n",
    "history = train_model(transfer_model, images, train_labels, epochs=10)\n",
    "\n",
    "# Save the model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "transfer_model.save('models/transfer_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Hyperparameters and Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Transfer Learning Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Transfer Learning Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
